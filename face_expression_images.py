# -*- coding: utf-8 -*-
"""face_Expression_images

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10fEgjmr7x6sP5DeE4AgMgPI9DfI5ef4h
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/gdrive')
# %cd /gdrive

import pandas as pd
import cv2
import numpy as np
 
dataset_path = '/gdrive/My Drive/fer2013.csv'
image_size=(48,48)

import sys, os
import pandas as pd
import numpy as np
import cv2
from keras.utils import to_categorical
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D
from keras.losses import categorical_crossentropy
from keras.optimizers import Adam
from keras.utils import np_utils
from keras.models import load_model

path = '/gdrive/My Drive/Emotion_Recognition'
sys.path.insert(0, path)
os.chdir(path)
#modelpath = './models/model.h5'

num_features = 32
num_classes = 7  
batch_size = 64
epochs = 100
width, height = 48, 48

data = pd.read_csv(dataset_path)
data.head()

#check target labels
emotion_map = {0: 'Angry', 1: 'Digust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}
emotion_counts = data['emotion'].value_counts(sort=False).reset_index()
emotion_counts.columns = ['emotion', 'number']
emotion_counts['emotion'] = emotion_counts['emotion'].map(emotion_map)
emotion_counts

# Plotting a bar graph of the class distributions
import matplotlib.pyplot as plt
plt.figure(figsize=(6,4))
plt.bar(emotion_counts.emotion, emotion_counts.number)
plt.title('Class distribution')
plt.ylabel('Number', fontsize=12)
plt.xlabel('Emotions', fontsize=12)
plt.show()

def pxl2image(row):
    pixels, emotion = row['pixels'], emotion_map[row['emotion']]
    img = np.array(pixels.split())
    img = img.reshape(48,48)
    image = np.zeros((48,48,3))
    image[:,:,0] = img
    image[:,:,1] = img
    image[:,:,2] = img
    return np.array([image.astype(np.uint8), emotion])

plt.figure(0, figsize=(16,10))
for i in range(1,8):
    face = data[data['emotion'] == i-1].iloc[0]
    img = pxl2image(face)
    plt.subplot(2,4,i)
    plt.imshow(img[0])
    plt.title(img[1])

plt.show()

data['pixels'] = data['pixels'].apply(lambda pixel_seq: [int(pixel) for pixel in pixel_seq.split()])

#split data into training, validation and test set
data_train = data[data['Usage']=='Training']
data_val   = data[data['Usage']=='PublicTest']
data_test  = data[data['Usage']=='PrivateTest']
print("train shape: {}, \nvalidation shape: {}, \ntest shape: {}".format(data_train.shape, data_val.shape, data_test.shape))

# barplot class distribution of train, val and test data
emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']

def setup_axe(axe,df,title):
    emotion_counts = df['emotion'].value_counts(sort=False)
    emotion_counts.plot(ax=axe, kind='bar')
    axe.set_xticklabels(emotion_labels)
    axe.set_xlabel("Emotions")
    axe.set_ylabel("Number")
    axe.set_title(title)
       
fig, axes = plt.subplots(1,3, figsize=(20,8), sharey=True)
setup_axe(axes[0],data_train,'train')
setup_axe(axes[1],data_val,'validation')
setup_axe(axes[2],data_test,'test')
plt.show()

#Converting the relevant column element into a list for each row
# (i) convert strings to lists of integers
# (ii) reshape and normalise grayscale image with 255.0
# (iii) one-hot encoding label, e.g. class 3 to [0,0,0,1,0,0,0]

def convert(df):
  # training data
  #data_train = data[data['Usage'] == 'Training']
  # reshape image data (num of images, width, height, num of channels)
  x = np.array(df['pixels'].tolist(), dtype='float32').reshape(-1,width,height,1)/255.0
  # get labels
  y = np_utils.to_categorical(df['emotion'])
  return x,y

# training data
data_train = data[data['Usage'] == 'Training']
x_train, y_train = convert(data_train)

# validation data
data_val = data[data['Usage'] == 'PublicTest']
x_val, y_val = convert(data_val)

# testing data
data_test = data[data['Usage'] == 'PrivateTest']
x_test, y_test = convert(data_test)

print('training data', x_train.shape, y_train.shape)
print('validation data', x_val.shape, y_val.shape)
print('testing data', x_test.shape, y_test.shape)

model = Sequential()

model.add(Conv2D(64, 3, input_shape=(48, 48, 1)))
model.add(BatchNormalization())
model.add(Activation("relu"))

model.add(Conv2D(64, 3))
model.add(BatchNormalization())
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(2, 2), strides=2))
model.add(Dropout(0.6))

model.add(Conv2D(32, 3))
model.add(BatchNormalization())
model.add(Activation("relu"))

model.add(Conv2D(32, 3))
model.add(BatchNormalization())
model.add(Activation("relu"))

model.add(Conv2D(32, 3))
model.add(BatchNormalization())
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(2, 2), strides=2))
model.add(Dropout(0.6))

model.add(Flatten())
model.add(Dense(128))
model.add(BatchNormalization())
model.add(Activation("relu"))
model.add(Dropout(0.6))

model.add(Dense(7))
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()

model.fit(np.array(x_train), np.array(y_train),batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(np.array(x_val), np.array(y_val)),shuffle=True)

import joblib
scores = model.evaluate(np.array(x_test), np.array(y_test), batch_size=batch_size)
print("CNN Error: %.2f%%" % (100-scores[1]*100))
print("Loss: " + str(scores[0]))
print("Accuracy: " + str(scores[1]))
joblib.dump(model, "expression-face.pkl")

test_true = np.argmax(y_test, axis=1)
test_pred = np.argmax(model.predict(x_test), axis=1)
print("CNN Model Accuracy on test set: {:.4f}".format(accuracy_score(test_true, test_pred)*100))

## test face emotion

from __future__ import division
#from keras.models import Sequential
from sklearn.externals import joblib
#from keras.layers import Dense
import numpy
#import os
import numpy as np
import cv2

#loading the model
model=joblib.load("/gdrive/My Drive/expression-face.pkl") 
print("Loaded model from disk")

#setting image resizing parameters
WIDTH = 48
HEIGHT = 48
x=None
y=None
labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']

#loading image
full_size_image = cv2.imread("/gdrive/My Drive/happy.jpg")
print("Image Loaded")
gray=cv2.cvtColor(full_size_image,cv2.COLOR_RGB2GRAY)
face_cascade=cv2.CascadeClassifier('/gdrive/My Drive/haarcascade_frontalface_default.xml')
faces = face_cascade.detectMultiScale(gray, 1.3  , 10)

#detecting faces
for (x, y, w, h) in faces:
        roi_gray = gray[y:y + h, x:x + w]
        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)
        cv2.normalize(cropped_img, cropped_img, alpha=0, beta=1, norm_type=cv2.NORM_L2, dtype=cv2.CV_32F)
        cv2.rectangle(full_size_image, (x, y), (x + w, y + h), (0, 255, 0), 1)
        #predicting the emotion
        yhat= model.predict(cropped_img)
        cv2.putText(full_size_image, labels[int(np.argmax(yhat))], (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 1, cv2.LINE_AA)
        print("Emotion: "+labels[int(np.argmax(yhat))])
        path = 'imgprd.png' #path to save the image
        cv2.imwrite(path,full_size_image)  #to save the image

cv2.imshow('Emotion', full_size_image)
cv2.waitKey()

